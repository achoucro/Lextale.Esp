#+TITLE: Final Project Report
#+DATE: Friday,August 11, 2023
#+AUTHORS: Ashley, Olive, Tee, Alina

* Introduction

Language proficiency assessment is an ever-evolving domain, where tools and techniques are constantly refined to meet contemporary requirements. One such significant tool is the LexTALE, or the Lexical Test for Advanced Learners of English. Introduced as a straightforward yet effective yes/no vocabulary test, its primary objective was to address the need for a practical approach to gauge relevant proficiency elements swiftly and uniformly across different research environments (Lemh√∂fer & Broersma, 2012). This tool not only offers insights into the vocabulary size of the participants but also serves as an indirect metric of their language proficiency. 
Drawing inspiration from this, our study seeks to adapt a Spanish version of the LexTALE for the English-speaking demographic in Canada, using Izura Cristina's "Lextale-Esp" as a foundational blueprint (Cristina, 2014). Besides the vocabulary size, another parameter of interest in our research is the reaction time. Reaction time in linguistic tasks often reflects the cognitive ease or difficulty a person encounters when processing linguistic information. It has been shown that elevated performance in lexical accuracy and response time significantly predicted reading proficiency (Sahiruddin, 2019). 
The foundational hypothesis steering this research posits that higher language proficiency would correlate with quicker reaction times, especially in distinguishing real words from non-words in Spanish. Through this, we aim to unveil the intricate relationship between vocabulary recognition speed and language mastery.


* Methods

*** Participants
This study utilized a convenience sample of 8 undergraduate students from the University of Waterloo. Gender, age, and ethnicity were not recorded in this study as these factors would not have a reliable or valid effect on the small sample size. 


*** Lextale Task
The Lextale-Esp includes 60 real Spanish words, and 30 words that resemble Spanish but are not real, for which we refer to as nonwords. The calculation of the total Lextale score is calculated based on the number of correctly identified real words and the number of correctly identified nonwords. Scores range from 0-1, with 1 being fully proficient. Below is the mathematical equation for the Lextale score:

/((number of words correct/40*100) + (number of nonwords correct/20*100)) / 2/

*** Computational and Statistical Tools 
For the analysis, the primary goal was to observe whether there was a correlation between higher language proficiency and quicker reaction time. To test this hypothesis, the statistical tools used were Pearson's coefficient and t-tests. 

The computational tools utilized to perform these statistical analyses were PsychoPy and R.

* Analysis and Results

#+begin_src R: session *R363* :exports both 
library(stats)

Data <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vQkuVRpJB4xKHsN86cGYBa75btj-SRnmnAMrmrUkDNcMOpy6LGo6OYJGpjTPKEKNMl6MOuXIfZhy2uc/pub?gid=0&single=true&output=csv")

Data$Proficiency_level <- Data$LexTALE_Score

threshold <- 0.484375

Data$Group <- ifelse(Data$Proficiency_level <= threshold, "High Proficiency", "Low Proficiency")

mean_high_proficiency <- mean(Data$Proficiency_level[Data$Group == "High Proficiency"], na.rm = TRUE)
mean_low_proficiency <- mean(Data$Proficiency_level[Data$Group == "Low Proficiency"], na.rm = TRUE) 
print(mean_high_proficiency)
print(mean_low_proficiency)  

sd_high_proficiency <- sd(Data$AverageResponseTime[Data$Group == "High Proficiency"])
sd_low_proficiency <- sd(Data$AverageResponseTime[Data$Group == "Low Proficiency"])
print(sd_high_proficiency)
print(sd_low_proficiency)

DescriptiveStatistics <- data.frame(
  Group = c("High Proficiency", "Low Proficiency"),
  StandardDeviation = c(sd_high_proficiency, sd_low_proficiency),
  Mean = c(mean_high_proficiency, mean_low_proficiency)
)
print(DescriptiveStatistics)

high_proficiency_data <- Data$AverageResponseTime[Data$Group == "High Proficiency"]
low_proficiency_data <- Data$AverageResponseTime[Data$Group == "Low Proficiency"]

t_test_result <- t.test(high_proficiency_data, low_proficiency_data)
print(t_test_result)

correlation <- cor(Data$LexTALE_Score, Data$AverageResponseTime, method = "pearson")
print(correlation)
#+end_src

In our study, we calculated participants' proficiency score by we took an average of the lextale score and used that average as a threshold for grouping. Those who scored above 0.484375 were considered in the High Proficiency group, while those below were placed in the Low Proficiency group. Given our small sample size of 8 participants, we found it appropriate to use the mean as our threshold.

To analyze the significance of the results, we opted for a t-test. This was because we had two distinct and independent groups, and we wanted to compare their average reaction times to determine if there was a significant difference in reaction times between the High and Low Proficiency groups. As well, we used R's statistical package to conduct a pearson's correlation test to see if there was any correlation between the lextale score and the average response time. 

We also used descriptive statistics to further examine our findings. Using the DescriptiveStatistics function, we generated a table that showed the mean and standard deviation for both the High and Low Proficiency groups. This allowed us to understand the average reaction times within each group and assess the variability or spread of data in each group. We separately calculated the mean average reaction time for each group. This helped us see if there was a trend of slower reaction times in the Low Proficiency group and faster reaction times in the High Proficiency group. Looking at standard deviations gave us insights into how consistent the reaction times were within each group.

*** Figure 1

#+BEGIN_SRC R :session *R363* :results file graphics replace :exports both :file "lextalegraph.png"
data <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vQkuVRpJB4xKHsN86cGYBa75btj-SRnmnAMrmrUkDNcMOpy6LGo6OYJGpjTPKEKNMl6MOuXIfZhy2uc/pub?gid=0&single=true&output=csv")
high_proficiency <- 0.4843750001
plot(data$AverageResponseTime,data$LexTALE_Score, 
     main= "Spanish Lextale Score vs Response Time",
     frame = F, 
     pch = 19, 
     col = ifelse(data$LexTALE_Score > high_proficiency, "green", "red"),
     ylab = "Spanish Lextale Score", 
     xlab = "Average Response Time", 
     lty = 1, 
     lwd = 3, 
     xlim=c(0.6, 2), 
     ylim=c(0.4, 0.6))
data_fit = lm(data$LexTALE_Score ~ data$AverageResponseTime)
summary(data_fit)
abline((data_fit), col = "black")
legend("topright", legend = c("High Proficiency", "Low Proficiency"),
       col = c("green", "red"), pch = 19)
#+END_SRC

Figure 1 demonstrates the relationship between participants' Lextale scores, also defined as their Proficiency Level and their average response time. Lextale scores that are considered to indicate high proficiency level are marked as green while scores that indicate low proficiency level are marked as red. 

* Discussion

In the present study, we looked at the correlation between participants' Lextale score and their response time. As demonstrated in our analysis, our Pearson correlation test gave us an r-value of -0.3826174, meaning that there is a weak negative correlation between one's Lextale score and response time. These findings are also evident in Figure 1. In addition, we investigated whether participants with high proficiency have a quicker average response time than those with low proficiency. We hypothesized that those who are highly proficient in a language should have faster reaction time in the recognition of real vs. nonwords. Our analysis revealed that this was not the case. Our t-test gave us a p-value of .4803. As this p-value is greater than .05, we found no significant difference in the response time between participants with high versus low proficiency. We fail to reject the null hypothesis. 

Our tests show that an individual's proficiency level in Spanish, based on Lextale scoring, does not determine how quickly one can recognize real from made-up Spanish words. These findings however may be due to our extremely small sample size (N=8). Future research could conduct a study with a larger sample size to ensure external validity (Faber & Fonseca, 2014). 

* References


